{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used to architect the data for a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trump counties:  2524\n",
      "Number of Biden counties:  503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "original_df = pd.read_csv('../data/data_election_2020.csv')\n",
    "\n",
    "\n",
    "num_trump = len(original_df[original_df['majority'] == 'Trump'])\n",
    "num_biden = len(original_df[original_df['majority'] == 'Biden'])\n",
    "\n",
    "print('Number of Trump counties: ', num_trump)\n",
    "print('Number of Biden counties: ', num_biden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('../data/county_to_be_merged.csv')\n",
    "merged_df = pd.merge(original_df, new_df, left_index=True, right_index=True)\n",
    "merged_df.to_csv('../data/merged_data_2020_election.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  `\"state\"   county majority  trump16  clinton16  otherpres16  romney12   \n",
      "0  Alabama  Autauga    Trump    18172       5936          865     17379  \\\n",
      "1  Alabama  Baldwin    Trump    72883      18458         3874     66016   \n",
      "2  Alabama  Barbour    Trump     5454       4871          144      5550   \n",
      "3  Alabama     Bibb    Trump     6738       1874          207      6132   \n",
      "4  Alabama   Blount    Trump    22859       2156          573     20757   \n",
      "\n",
      "   obama12  otherpres12  demsen16  ...  poverty_under_18_2019   \n",
      "0     6363          190    6331.0  ...                   23.2  \\\n",
      "1    18424          898   19145.0  ...                   13.4   \n",
      "2     5912           47    4777.0  ...                   50.1   \n",
      "3     2202           86    2082.0  ...                    NaN   \n",
      "4     2970          279    2980.0  ...                   18.4   \n",
      "\n",
      "   two_plus_races_2019  unemployment_rate_2019  uninsured_2019   \n",
      "0                  2.2                     3.5             7.1  \\\n",
      "1                  1.7                     4.0             8.9   \n",
      "2                  1.2                     9.4            11.3   \n",
      "3                  0.6                     7.0            10.7   \n",
      "4                  1.6                     3.1            10.8   \n",
      "\n",
      "   uninsured_65_and_older_2019  uninsured_under_19_2019   \n",
      "0                          0.0                      1.7  \\\n",
      "1                          0.3                      3.8   \n",
      "2                          0.3                      3.3   \n",
      "3                          0.0                      2.0   \n",
      "4                          0.2                      5.9   \n",
      "\n",
      "   uninsured_under_6_2019  veterans_2019  white_2019  white_not_hispanic_2019  \n",
      "0                     1.7           12.6        76.8                     74.6  \n",
      "1                     2.2           11.8        86.2                     83.1  \n",
      "2                     3.4            6.6        46.8                     45.8  \n",
      "3                     4.5            8.0        76.8                     74.5  \n",
      "4                     6.1            7.7        95.5                     86.9  \n",
      "\n",
      "[5 rows x 118 columns]\n",
      "Number of columns 118\n",
      "['`\"state\"', 'county', 'majority', 'trump16', 'clinton16', 'otherpres16', 'romney12', 'obama12', 'otherpres12', 'demsen16', 'repsen16', 'othersen16', 'demhouse16', 'rephouse16', 'otherhouse16', 'total_population', 'cvap', 'white_pct', 'black_pct', 'hispanic_pct', 'nonwhite_pct', 'foreignborn_pct', 'female_pct', 'age29andunder_pct', 'age65andolder_pct', 'median_hh_inc', 'clf_unemploy_pct', 'lesshs_pct', 'lesscollege_pct', 'lesshs_whites_pct', 'lesscollege_whites_pct', 'rural_pct', 'fips', 'state', 'name', 'age_under_5_2017', 'age_over_65_2017', 'median_age_2017', 'female_2010', 'white_2010', 'black_2017', 'native_2017', 'asian_2017', 'pac_isl_2017', 'other_single_race_2017', 'two_plus_races_2017', 'hispanic_2017', 'white_not_hispanic_2017', 'speak_english_only_2017', 'women_16_to_50_birth_rate_2017', 'hs_grad_2017', 'some_college_2017', 'bachelors_2017', 'veterans_2017', 'mean_work_travel_2017', 'broadband_2017', 'computer_2017', 'households_2017', 'persons_per_household_2017', 'per_capita_income_2017', 'median_household_income_2017', 'poverty_2017', 'poverty_age_under_5_2017', 'poverty_age_under_18_2017', 'uninsured_2017', 'uninsured_age_under_6_2017', 'uninsured_age_under_19_2017', 'uninsured_age_over_74_2017', 'civilian_labor_force_2017', 'employed_2017', 'unemployed_2017', 'unemployment_rate_2017', 'age_over_18_2019', 'age_over_65_2019', 'age_over_85_2019', 'age_under_5_2019', 'asian_2019', 'avg_family_size_2019', 'bachelors_2019', 'black_2019', 'hispanic_2019', 'household_has_broadband_2019', 'household_has_computer_2019', 'household_has_smartphone_2019', 'households_2019', 'households_speak_asian_or_pac_isl_2019', 'households_speak_limited_english_2019', 'households_speak_other_2019', 'households_speak_other_indo_euro_lang_2019', 'households_speak_spanish_2019', 'housing_mobile_homes_2019', 'housing_one_unit_structures_2019', 'housing_two_unit_structures_2019', 'hs_grad_2019', 'mean_household_income_2019', 'mean_work_travel_2019', 'median_age_2019', 'median_household_income_2019', 'median_individual_income_2019', 'median_individual_income_age_25plus_2019', 'native_2019', 'other_single_race_2019', 'pac_isl_2019', 'per_capita_income_2019', 'persons_per_household_2019', 'pop_2019', 'poverty_2019', 'poverty_65_and_over_2019', 'poverty_under_18_2019', 'two_plus_races_2019', 'unemployment_rate_2019', 'uninsured_2019', 'uninsured_65_and_older_2019', 'uninsured_under_19_2019', 'uninsured_under_6_2019', 'veterans_2019', 'white_2019', 'white_not_hispanic_2019']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())\n",
    "col_list = list(merged_df.columns)\n",
    "print(f\"Number of columns {len(col_list)}\")\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  `\"state\"   county majority  trump16  clinton16  otherpres16  romney12   \n",
      "0  Alabama  Autauga    Trump    18172       5936          865     17379  \\\n",
      "1  Alabama  Baldwin    Trump    72883      18458         3874     66016   \n",
      "2  Alabama  Barbour    Trump     5454       4871          144      5550   \n",
      "3  Alabama     Bibb    Trump     6738       1874          207      6132   \n",
      "4  Alabama   Blount    Trump    22859       2156          573     20757   \n",
      "\n",
      "   obama12  otherpres12  demsen16  ...  poverty_under_18_2019   \n",
      "0     6363          190    6331.0  ...                   23.2  \\\n",
      "1    18424          898   19145.0  ...                   13.4   \n",
      "2     5912           47    4777.0  ...                   50.1   \n",
      "3     2202           86    2082.0  ...                    NaN   \n",
      "4     2970          279    2980.0  ...                   18.4   \n",
      "\n",
      "   two_plus_races_2019  unemployment_rate_2019  uninsured_2019   \n",
      "0                  2.2                     3.5             7.1  \\\n",
      "1                  1.7                     4.0             8.9   \n",
      "2                  1.2                     9.4            11.3   \n",
      "3                  0.6                     7.0            10.7   \n",
      "4                  1.6                     3.1            10.8   \n",
      "\n",
      "   uninsured_65_and_older_2019  uninsured_under_19_2019   \n",
      "0                          0.0                      1.7  \\\n",
      "1                          0.3                      3.8   \n",
      "2                          0.3                      3.3   \n",
      "3                          0.0                      2.0   \n",
      "4                          0.2                      5.9   \n",
      "\n",
      "   uninsured_under_6_2019  veterans_2019  white_2019  white_not_hispanic_2019  \n",
      "0                     1.7           12.6        76.8                     74.6  \n",
      "1                     2.2           11.8        86.2                     83.1  \n",
      "2                     3.4            6.6        46.8                     45.8  \n",
      "3                     4.5            8.0        76.8                     74.5  \n",
      "4                     6.1            7.7        95.5                     86.9  \n",
      "\n",
      "[5 rows x 118 columns]\n",
      "Number of columns 118\n",
      "['`\"state\"', 'county', 'majority', 'trump16', 'clinton16', 'otherpres16', 'romney12', 'obama12', 'otherpres12', 'demsen16', 'repsen16', 'othersen16', 'demhouse16', 'rephouse16', 'otherhouse16', 'total_population', 'cvap', 'white_pct', 'black_pct', 'hispanic_pct', 'nonwhite_pct', 'foreignborn_pct', 'female_pct', 'age29andunder_pct', 'age65andolder_pct', 'median_hh_inc', 'clf_unemploy_pct', 'lesshs_pct', 'lesscollege_pct', 'lesshs_whites_pct', 'lesscollege_whites_pct', 'rural_pct', 'fips', 'state', 'name', 'age_under_5_2017', 'age_over_65_2017', 'median_age_2017', 'female_2010', 'white_2010', 'black_2017', 'native_2017', 'asian_2017', 'pac_isl_2017', 'other_single_race_2017', 'two_plus_races_2017', 'hispanic_2017', 'white_not_hispanic_2017', 'speak_english_only_2017', 'women_16_to_50_birth_rate_2017', 'hs_grad_2017', 'some_college_2017', 'bachelors_2017', 'veterans_2017', 'mean_work_travel_2017', 'broadband_2017', 'computer_2017', 'households_2017', 'persons_per_household_2017', 'per_capita_income_2017', 'median_household_income_2017', 'poverty_2017', 'poverty_age_under_5_2017', 'poverty_age_under_18_2017', 'uninsured_2017', 'uninsured_age_under_6_2017', 'uninsured_age_under_19_2017', 'uninsured_age_over_74_2017', 'civilian_labor_force_2017', 'employed_2017', 'unemployed_2017', 'unemployment_rate_2017', 'age_over_18_2019', 'age_over_65_2019', 'age_over_85_2019', 'age_under_5_2019', 'asian_2019', 'avg_family_size_2019', 'bachelors_2019', 'black_2019', 'hispanic_2019', 'household_has_broadband_2019', 'household_has_computer_2019', 'household_has_smartphone_2019', 'households_2019', 'households_speak_asian_or_pac_isl_2019', 'households_speak_limited_english_2019', 'households_speak_other_2019', 'households_speak_other_indo_euro_lang_2019', 'households_speak_spanish_2019', 'housing_mobile_homes_2019', 'housing_one_unit_structures_2019', 'housing_two_unit_structures_2019', 'hs_grad_2019', 'mean_household_income_2019', 'mean_work_travel_2019', 'median_age_2019', 'median_household_income_2019', 'median_individual_income_2019', 'median_individual_income_age_25plus_2019', 'native_2019', 'other_single_race_2019', 'pac_isl_2019', 'per_capita_income_2019', 'persons_per_household_2019', 'pop_2019', 'poverty_2019', 'poverty_65_and_over_2019', 'poverty_under_18_2019', 'two_plus_races_2019', 'unemployment_rate_2019', 'uninsured_2019', 'uninsured_65_and_older_2019', 'uninsured_under_19_2019', 'uninsured_under_6_2019', 'veterans_2019', 'white_2019', 'white_not_hispanic_2019']\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_csv('../data/merged_data_2020_election.csv')\n",
    "print(new_df.head())\n",
    "col_list = list(new_df.columns)\n",
    "print(f\"Number of columns {len(col_list)}\")\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "# Fix the 'uninsured' dtype rendering as type 'object'ArithmeticError\n",
    "new_df = pd.read_csv('../data/merged_data_2020_election.csv')\n",
    "non_numerical_cols = new_df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "non_numerical_cols = list(non_numerical_cols)\n",
    "new_df['uninsured_age_under_6_2017'] = new_df['uninsured_age_under_6_2017'].apply(lambda x: x if x != '-' else 0)\n",
    "new_df['uninsured_age_under_6_2017'] = new_df['uninsured_age_under_6_2017'].astype('float64')\n",
    "# Encode the categorical columns\n",
    "columns_to_encode = ['state', 'majority']\n",
    "new_df = new_df.drop('county', axis=1, inplace=False)\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_columns = one_hot_encoder.fit_transform(new_df[columns_to_encode])\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=one_hot_encoder.get_feature_names_out(columns_to_encode))\n",
    "new_df = pd.concat([new_df, encoded_df], axis=1)\n",
    "new_df.drop(columns=columns_to_encode, inplace=True)\n",
    "merged_encoded_df = new_df.to_csv('../data/merged_encoded_data_2020_election.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.050101 -0.187409 -0.211717 -0.049035 -0.197572 -0.220460 -0.229879   \n",
      "1  1.205277 -0.033304  0.185099  1.032118 -0.036067  0.016656 -0.079023   \n",
      "2 -0.341923 -0.200515 -0.306800 -0.311982 -0.203612 -0.268352 -0.248174   \n",
      "3 -0.312461 -0.237399 -0.298492 -0.299045 -0.253291 -0.255290 -0.279901   \n",
      "4  0.057446 -0.233928 -0.250225  0.026055 -0.243007 -0.190653 -0.269329   \n",
      "\n",
      "        7         8         9    ...       151       152       153       154  \\\n",
      "0 -0.057110 -0.423608 -0.172514  ... -0.146968 -0.177048 -0.300696 -0.098352   \n",
      "1  1.785669 -0.377874 -0.268999  ... -0.146968 -0.177048 -0.300696 -0.098352   \n",
      "2 -0.479291 -0.434918 -0.201253  ... -0.146968 -0.177048 -0.300696 -0.098352   \n",
      "3 -0.440454 -0.434672 -0.243791  ... -0.146968 -0.177048 -0.300696 -0.098352   \n",
      "4  0.073302 -0.427050 -0.238432  ... -0.146968 -0.177048 -0.300696 -0.098352   \n",
      "\n",
      "        155       156       157       158      159       160  \n",
      "0 -0.068165 -0.182917 -0.114246 -0.134772 -0.15498 -0.087501  \n",
      "1 -0.068165 -0.182917 -0.114246 -0.134772 -0.15498 -0.087501  \n",
      "2 -0.068165 -0.182917 -0.114246 -0.134772 -0.15498 -0.087501  \n",
      "3 -0.068165 -0.182917 -0.114246 -0.134772 -0.15498 -0.087501  \n",
      "4 -0.068165 -0.182917 -0.114246 -0.134772 -0.15498 -0.087501  \n",
      "\n",
      "[5 rows x 161 columns]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "Name: majority_Biden, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.read_csv('../output/merged_encoded_data_2020_election.csv')\n",
    "df = df.drop(columns=['state.1', 'name', 'fips', 'majority_Trump'], axis=1, inplace=False)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(imp.fit_transform(df), columns=df.columns)\n",
    "X = df_imputed.drop('majority_Biden', axis=1, inplace=False)\n",
    "X = pd.DataFrame(scaler.fit_transform(X))\n",
    "y = df_imputed['majority_Biden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train / test split - Note that I dropped majority_Trump since Biden will be 0 or 1 indicating Trump or Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecting out the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 4ms/step - loss: 0.3493 - accuracy: 0.8629\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9170\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9467\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9612\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9748\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9864\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9905\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9913\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9934\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9959\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9963\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9950\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9897\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9855\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9971\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9988\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9992\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 9.8465e-04 - accuracy: 0.9996\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.3965e-04 - accuracy: 0.9996\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.4084e-04 - accuracy: 0.9996\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2410e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2818e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.5312e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.0078e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.4550e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0627e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.7196e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4545e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2030e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9886e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8343e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6600e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5229e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4055e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2992e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1978e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1194e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0513e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.7703e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.1865e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.5617e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.0457e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.5731e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1579e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7490e-05 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4620e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0798e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7642e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4678e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2040e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9455e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.7410e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.5123e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.3025e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.1019e-05 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9058e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.7715e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5934e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.4343e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3048e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1628e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0301e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9178e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7954e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6786e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5924e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4808e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4004e-05 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.3024e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2218e-05 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.1374e-05 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0601e-05 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9891e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9203e-05 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8514e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7820e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7270e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6599e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6084e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5511e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5054e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4593e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4048e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3561e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3160e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2707e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2352e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1933e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1570e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1229e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0847e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0557e-05 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.9488\n",
      "Accuracy: 0.9488449096679688\n"
     ]
    }
   ],
   "source": [
    "# Let's architect out the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(161, input_dim=len(X_train.columns), activation='relu')) \n",
    "model.add(Dense(81, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have heavily overfitted the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 19ms/step - loss: 1.1245 - accuracy: 0.6059 - val_loss: 0.8224 - val_accuracy: 0.8289\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.9288 - accuracy: 0.7417 - val_loss: 0.7883 - val_accuracy: 0.8351\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.8466 - accuracy: 0.7939 - val_loss: 0.7214 - val_accuracy: 0.8351\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.8030 - accuracy: 0.8208 - val_loss: 0.6837 - val_accuracy: 0.8433\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7582 - accuracy: 0.8316 - val_loss: 0.6337 - val_accuracy: 0.8474\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.7008 - accuracy: 0.8383 - val_loss: 0.5987 - val_accuracy: 0.8557\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6664 - accuracy: 0.8337 - val_loss: 0.5742 - val_accuracy: 0.8701\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6307 - accuracy: 0.8543 - val_loss: 0.5572 - val_accuracy: 0.8969\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5956 - accuracy: 0.8647 - val_loss: 0.5503 - val_accuracy: 0.8866\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5837 - accuracy: 0.8765 - val_loss: 0.5343 - val_accuracy: 0.8990\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5589 - accuracy: 0.8714 - val_loss: 0.5229 - val_accuracy: 0.8948\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5092 - accuracy: 0.8926 - val_loss: 0.5130 - val_accuracy: 0.9052\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.9019 - val_loss: 0.5068 - val_accuracy: 0.8928\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4840 - accuracy: 0.8993 - val_loss: 0.5011 - val_accuracy: 0.8928\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.9101 - val_loss: 0.4891 - val_accuracy: 0.8907\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.9194 - val_loss: 0.4735 - val_accuracy: 0.9031\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4316 - accuracy: 0.9189 - val_loss: 0.4741 - val_accuracy: 0.9031\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.9205 - val_loss: 0.4652 - val_accuracy: 0.9072\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.9308 - val_loss: 0.4577 - val_accuracy: 0.9093\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.9329 - val_loss: 0.4586 - val_accuracy: 0.9052\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.9365 - val_loss: 0.4431 - val_accuracy: 0.9052\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.9292 - val_loss: 0.4402 - val_accuracy: 0.9155\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.9313 - val_loss: 0.4336 - val_accuracy: 0.9155\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3624 - accuracy: 0.9370 - val_loss: 0.4397 - val_accuracy: 0.9052\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.9489 - val_loss: 0.4274 - val_accuracy: 0.9093\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.9478 - val_loss: 0.4277 - val_accuracy: 0.9072\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3358 - accuracy: 0.9483 - val_loss: 0.4236 - val_accuracy: 0.9093\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.9597 - val_loss: 0.4103 - val_accuracy: 0.9093\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.9540 - val_loss: 0.4068 - val_accuracy: 0.9134\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3111 - accuracy: 0.9520 - val_loss: 0.4227 - val_accuracy: 0.9155\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3030 - accuracy: 0.9535 - val_loss: 0.4157 - val_accuracy: 0.9196\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 0.9602 - val_loss: 0.3882 - val_accuracy: 0.9155\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.9675 - val_loss: 0.3947 - val_accuracy: 0.9175\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2843 - accuracy: 0.9571 - val_loss: 0.4235 - val_accuracy: 0.9134\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2748 - accuracy: 0.9638 - val_loss: 0.4263 - val_accuracy: 0.9072\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2617 - accuracy: 0.9669 - val_loss: 0.4247 - val_accuracy: 0.9113\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2652 - accuracy: 0.9644 - val_loss: 0.4122 - val_accuracy: 0.9134\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2644 - accuracy: 0.9649 - val_loss: 0.4173 - val_accuracy: 0.9093\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2646 - accuracy: 0.9644 - val_loss: 0.3829 - val_accuracy: 0.9134\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2444 - accuracy: 0.9695 - val_loss: 0.4161 - val_accuracy: 0.9155\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2308 - accuracy: 0.9819 - val_loss: 0.4022 - val_accuracy: 0.9113\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2407 - accuracy: 0.9721 - val_loss: 0.3903 - val_accuracy: 0.9155\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2346 - accuracy: 0.9752 - val_loss: 0.4028 - val_accuracy: 0.9113\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2292 - accuracy: 0.9788 - val_loss: 0.3948 - val_accuracy: 0.9134\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2397 - accuracy: 0.9685 - val_loss: 0.4091 - val_accuracy: 0.9031\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.9742 - val_loss: 0.4023 - val_accuracy: 0.9052\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2040 - accuracy: 0.9814 - val_loss: 0.4190 - val_accuracy: 0.9093\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2059 - accuracy: 0.9788 - val_loss: 0.4547 - val_accuracy: 0.9093\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1995 - accuracy: 0.9804 - val_loss: 0.4399 - val_accuracy: 0.9155\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.9241\n",
      "Accuracy: 0.9240924119949341\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(161, input_dim=len(X_train.columns), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(81, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(40, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a grid CV search to optimise the best hyperparameters. Note: I have changed the evaluation metric to F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I want to oversample the minority class\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Odhran\\Documents\\statistical_analysis_3\\python_scripts\\data_set_up.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Dropout\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscikit_learn\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasClassifier\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2 \u001b[39mas\u001b[39;00m _tf2\n\u001b[0;32m     46\u001b[0m _tf2\u001b[39m.\u001b[39menable()\n\u001b[1;32m---> 48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m __internal__\n\u001b[0;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m __operators__\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m eager_context\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m function\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_api\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m__internal__\u001b[39;00m \u001b[39mimport\u001b[39;00m graph_util\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\feature_column\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m\"\"\"Public API for tf._api.v2.__internal__.feature_column namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m DenseColumn \u001b[39m# line: 1983\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m FeatureTransformationCache \u001b[39m# line: 2168\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m SequenceDenseColumn \u001b[39m# line: 2147\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_v2.py:137\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m readers\n\u001b[0;32m    136\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m--> 137\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column \u001b[39mas\u001b[39;00m fc_old\n\u001b[0;32m    138\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m feature_column_v2_types \u001b[39mas\u001b[39;00m fc_types\n\u001b[0;32m    139\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_column\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py:143\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor \u001b[39mas\u001b[39;00m sparse_tensor_lib\n\u001b[0;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n\u001b[1;32m--> 143\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[0;32m    144\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops\n\u001b[0;32m    145\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m array_ops_stack\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\layers\\base.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# =============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy_tf_layers\u001b[39;00m \u001b[39mimport\u001b[39;00m base\n\u001b[0;32m     18\u001b[0m InputSpec \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mInputSpec\n\u001b[0;32m     20\u001b[0m keras_style_scope \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mkeras_style_scope\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\models.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m sequential\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_v1\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m AddMetric\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Layer\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training \u001b[39mas\u001b[39;00m training_lib\n\u001b[1;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_arrays_v1\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_distributed_v1\n\u001b[0;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m training_eager_v1\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m nest\n\u001b[0;32m     36\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse  \u001b[39m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m   issparse \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\sparse\\__init__.py:286\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m csgraph\n\u001b[0;32m    285\u001b[0m \u001b[39m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m    287\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[0;32m    288\u001b[0m     lil, sparsetools, sputils\n\u001b[0;32m    289\u001b[0m )\n\u001b[0;32m    291\u001b[0m __all__ \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m() \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m    293\u001b[0m \u001b[39m# Filter PendingDeprecationWarning for np.matrix introduced with numpy 1.15\u001b[39;00m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1430\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1402\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1535\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.caallbacks import EarlyStopping\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "def create_model(dropout_rate=0.0, regularization_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(161, input_dim=len(X_train_resampled.columns), activation='relu', kernel_regularizer=l2(regularization_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=64, verbose=0)\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'regularization_rate': [0.001, 0.01],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [50, 100],\n",
    "    'init_mode': ['uniform', 'normal'],\n",
    "    'activation': ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=f1_scorer, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_resampled, y_train_resampled)\n",
    "print(f'Best F1 Score: {grid_result.best_score_} using {grid_result.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best F1 Score: 0.9748581014730419 using {'model__activation': 'relu', 'model__dropout_rate': 0.5, 'model__init_mode': 'normal', 'model__optimizer': 'adam', 'model__regularization_rate': 0.001}\n",
    "This is the best model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
