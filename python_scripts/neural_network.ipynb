{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used to architect the data for a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trump counties:  2524\n",
      "Number of Biden counties:  503\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "original_df = pd.read_csv('../data/data_election_2020.csv')\n",
    "\n",
    "\n",
    "num_trump = len(original_df[original_df['majority'] == 'Trump'])\n",
    "\n",
    "num_biden = len(original_df[original_df['majority'] == 'Biden'])\n",
    "\n",
    "print('Number of Trump counties: ', num_trump)\n",
    "print('Number of Biden counties: ', num_biden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('../data/county_to_be_merged.csv')\n",
    "merged_df = pd.merge(original_df, new_df, left_index=True, right_index=True)\n",
    "merged_df.to_csv('../data/merged_data_2020_election.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  `\"state\"   county majority  trump16  clinton16  otherpres16  romney12  \\\n",
      "0  Alabama  Autauga    Trump    18172       5936          865     17379   \n",
      "1  Alabama  Baldwin    Trump    72883      18458         3874     66016   \n",
      "2  Alabama  Barbour    Trump     5454       4871          144      5550   \n",
      "3  Alabama     Bibb    Trump     6738       1874          207      6132   \n",
      "4  Alabama   Blount    Trump    22859       2156          573     20757   \n",
      "\n",
      "   obama12  otherpres12  demsen16  ...  poverty_under_18_2019  \\\n",
      "0     6363          190    6331.0  ...                   23.2   \n",
      "1    18424          898   19145.0  ...                   13.4   \n",
      "2     5912           47    4777.0  ...                   50.1   \n",
      "3     2202           86    2082.0  ...                    NaN   \n",
      "4     2970          279    2980.0  ...                   18.4   \n",
      "\n",
      "   two_plus_races_2019  unemployment_rate_2019  uninsured_2019  \\\n",
      "0                  2.2                     3.5             7.1   \n",
      "1                  1.7                     4.0             8.9   \n",
      "2                  1.2                     9.4            11.3   \n",
      "3                  0.6                     7.0            10.7   \n",
      "4                  1.6                     3.1            10.8   \n",
      "\n",
      "   uninsured_65_and_older_2019  uninsured_under_19_2019  \\\n",
      "0                          0.0                      1.7   \n",
      "1                          0.3                      3.8   \n",
      "2                          0.3                      3.3   \n",
      "3                          0.0                      2.0   \n",
      "4                          0.2                      5.9   \n",
      "\n",
      "   uninsured_under_6_2019  veterans_2019  white_2019  white_not_hispanic_2019  \n",
      "0                     1.7           12.6        76.8                     74.6  \n",
      "1                     2.2           11.8        86.2                     83.1  \n",
      "2                     3.4            6.6        46.8                     45.8  \n",
      "3                     4.5            8.0        76.8                     74.5  \n",
      "4                     6.1            7.7        95.5                     86.9  \n",
      "\n",
      "[5 rows x 118 columns]\n",
      "Number of columns 118\n",
      "['`\"state\"', 'county', 'majority', 'trump16', 'clinton16', 'otherpres16', 'romney12', 'obama12', 'otherpres12', 'demsen16', 'repsen16', 'othersen16', 'demhouse16', 'rephouse16', 'otherhouse16', 'total_population', 'cvap', 'white_pct', 'black_pct', 'hispanic_pct', 'nonwhite_pct', 'foreignborn_pct', 'female_pct', 'age29andunder_pct', 'age65andolder_pct', 'median_hh_inc', 'clf_unemploy_pct', 'lesshs_pct', 'lesscollege_pct', 'lesshs_whites_pct', 'lesscollege_whites_pct', 'rural_pct', 'fips', 'state', 'name', 'age_under_5_2017', 'age_over_65_2017', 'median_age_2017', 'female_2010', 'white_2010', 'black_2017', 'native_2017', 'asian_2017', 'pac_isl_2017', 'other_single_race_2017', 'two_plus_races_2017', 'hispanic_2017', 'white_not_hispanic_2017', 'speak_english_only_2017', 'women_16_to_50_birth_rate_2017', 'hs_grad_2017', 'some_college_2017', 'bachelors_2017', 'veterans_2017', 'mean_work_travel_2017', 'broadband_2017', 'computer_2017', 'households_2017', 'persons_per_household_2017', 'per_capita_income_2017', 'median_household_income_2017', 'poverty_2017', 'poverty_age_under_5_2017', 'poverty_age_under_18_2017', 'uninsured_2017', 'uninsured_age_under_6_2017', 'uninsured_age_under_19_2017', 'uninsured_age_over_74_2017', 'civilian_labor_force_2017', 'employed_2017', 'unemployed_2017', 'unemployment_rate_2017', 'age_over_18_2019', 'age_over_65_2019', 'age_over_85_2019', 'age_under_5_2019', 'asian_2019', 'avg_family_size_2019', 'bachelors_2019', 'black_2019', 'hispanic_2019', 'household_has_broadband_2019', 'household_has_computer_2019', 'household_has_smartphone_2019', 'households_2019', 'households_speak_asian_or_pac_isl_2019', 'households_speak_limited_english_2019', 'households_speak_other_2019', 'households_speak_other_indo_euro_lang_2019', 'households_speak_spanish_2019', 'housing_mobile_homes_2019', 'housing_one_unit_structures_2019', 'housing_two_unit_structures_2019', 'hs_grad_2019', 'mean_household_income_2019', 'mean_work_travel_2019', 'median_age_2019', 'median_household_income_2019', 'median_individual_income_2019', 'median_individual_income_age_25plus_2019', 'native_2019', 'other_single_race_2019', 'pac_isl_2019', 'per_capita_income_2019', 'persons_per_household_2019', 'pop_2019', 'poverty_2019', 'poverty_65_and_over_2019', 'poverty_under_18_2019', 'two_plus_races_2019', 'unemployment_rate_2019', 'uninsured_2019', 'uninsured_65_and_older_2019', 'uninsured_under_19_2019', 'uninsured_under_6_2019', 'veterans_2019', 'white_2019', 'white_not_hispanic_2019']\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head())\n",
    "col_list = list(merged_df.columns)\n",
    "print(f\"Number of columns {len(col_list)}\")\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  `\"state\"   county majority  trump16  clinton16  otherpres16  romney12  \\\n",
      "0  Alabama  Autauga    Trump    18172       5936          865     17379   \n",
      "1  Alabama  Baldwin    Trump    72883      18458         3874     66016   \n",
      "2  Alabama  Barbour    Trump     5454       4871          144      5550   \n",
      "3  Alabama     Bibb    Trump     6738       1874          207      6132   \n",
      "4  Alabama   Blount    Trump    22859       2156          573     20757   \n",
      "\n",
      "   obama12  otherpres12  demsen16  ...  poverty_under_18_2019  \\\n",
      "0     6363          190    6331.0  ...                   23.2   \n",
      "1    18424          898   19145.0  ...                   13.4   \n",
      "2     5912           47    4777.0  ...                   50.1   \n",
      "3     2202           86    2082.0  ...                    NaN   \n",
      "4     2970          279    2980.0  ...                   18.4   \n",
      "\n",
      "   two_plus_races_2019  unemployment_rate_2019  uninsured_2019  \\\n",
      "0                  2.2                     3.5             7.1   \n",
      "1                  1.7                     4.0             8.9   \n",
      "2                  1.2                     9.4            11.3   \n",
      "3                  0.6                     7.0            10.7   \n",
      "4                  1.6                     3.1            10.8   \n",
      "\n",
      "   uninsured_65_and_older_2019  uninsured_under_19_2019  \\\n",
      "0                          0.0                      1.7   \n",
      "1                          0.3                      3.8   \n",
      "2                          0.3                      3.3   \n",
      "3                          0.0                      2.0   \n",
      "4                          0.2                      5.9   \n",
      "\n",
      "   uninsured_under_6_2019  veterans_2019  white_2019  white_not_hispanic_2019  \n",
      "0                     1.7           12.6        76.8                     74.6  \n",
      "1                     2.2           11.8        86.2                     83.1  \n",
      "2                     3.4            6.6        46.8                     45.8  \n",
      "3                     4.5            8.0        76.8                     74.5  \n",
      "4                     6.1            7.7        95.5                     86.9  \n",
      "\n",
      "[5 rows x 118 columns]\n",
      "Number of columns 118\n",
      "['`\"state\"', 'county', 'majority', 'trump16', 'clinton16', 'otherpres16', 'romney12', 'obama12', 'otherpres12', 'demsen16', 'repsen16', 'othersen16', 'demhouse16', 'rephouse16', 'otherhouse16', 'total_population', 'cvap', 'white_pct', 'black_pct', 'hispanic_pct', 'nonwhite_pct', 'foreignborn_pct', 'female_pct', 'age29andunder_pct', 'age65andolder_pct', 'median_hh_inc', 'clf_unemploy_pct', 'lesshs_pct', 'lesscollege_pct', 'lesshs_whites_pct', 'lesscollege_whites_pct', 'rural_pct', 'fips', 'state', 'name', 'age_under_5_2017', 'age_over_65_2017', 'median_age_2017', 'female_2010', 'white_2010', 'black_2017', 'native_2017', 'asian_2017', 'pac_isl_2017', 'other_single_race_2017', 'two_plus_races_2017', 'hispanic_2017', 'white_not_hispanic_2017', 'speak_english_only_2017', 'women_16_to_50_birth_rate_2017', 'hs_grad_2017', 'some_college_2017', 'bachelors_2017', 'veterans_2017', 'mean_work_travel_2017', 'broadband_2017', 'computer_2017', 'households_2017', 'persons_per_household_2017', 'per_capita_income_2017', 'median_household_income_2017', 'poverty_2017', 'poverty_age_under_5_2017', 'poverty_age_under_18_2017', 'uninsured_2017', 'uninsured_age_under_6_2017', 'uninsured_age_under_19_2017', 'uninsured_age_over_74_2017', 'civilian_labor_force_2017', 'employed_2017', 'unemployed_2017', 'unemployment_rate_2017', 'age_over_18_2019', 'age_over_65_2019', 'age_over_85_2019', 'age_under_5_2019', 'asian_2019', 'avg_family_size_2019', 'bachelors_2019', 'black_2019', 'hispanic_2019', 'household_has_broadband_2019', 'household_has_computer_2019', 'household_has_smartphone_2019', 'households_2019', 'households_speak_asian_or_pac_isl_2019', 'households_speak_limited_english_2019', 'households_speak_other_2019', 'households_speak_other_indo_euro_lang_2019', 'households_speak_spanish_2019', 'housing_mobile_homes_2019', 'housing_one_unit_structures_2019', 'housing_two_unit_structures_2019', 'hs_grad_2019', 'mean_household_income_2019', 'mean_work_travel_2019', 'median_age_2019', 'median_household_income_2019', 'median_individual_income_2019', 'median_individual_income_age_25plus_2019', 'native_2019', 'other_single_race_2019', 'pac_isl_2019', 'per_capita_income_2019', 'persons_per_household_2019', 'pop_2019', 'poverty_2019', 'poverty_65_and_over_2019', 'poverty_under_18_2019', 'two_plus_races_2019', 'unemployment_rate_2019', 'uninsured_2019', 'uninsured_65_and_older_2019', 'uninsured_under_19_2019', 'uninsured_under_6_2019', 'veterans_2019', 'white_2019', 'white_not_hispanic_2019']\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_csv('../data/merged_data_2020_election.csv')\n",
    "print(new_df.head())\n",
    "col_list = list(new_df.columns)\n",
    "print(f\"Number of columns {len(col_list)}\")\n",
    "print(col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to perform one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Odhran\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "# Fix the 'uninsured' dtype rendering as type 'object'ArithmeticError\n",
    "new_df = pd.read_csv('../data/merged_data_2020_election.csv')\n",
    "non_numerical_cols = new_df.select_dtypes(exclude=['int64', 'float64']).columns\n",
    "non_numerical_cols = list(non_numerical_cols)\n",
    "new_df['uninsured_age_under_6_2017'] = new_df['uninsured_age_under_6_2017'].apply(lambda x: x if x != '-' else 0)\n",
    "new_df['uninsured_age_under_6_2017'] = new_df['uninsured_age_under_6_2017'].astype('float64')\n",
    "# Encode the categorical columns\n",
    "columns_to_encode = ['state', 'majority']\n",
    "new_df = new_df.drop('county', axis=1, inplace=False)\n",
    "one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_columns = one_hot_encoder.fit_transform(new_df[columns_to_encode])\n",
    "encoded_df = pd.DataFrame(encoded_columns, columns=one_hot_encoder.get_feature_names_out(columns_to_encode))\n",
    "new_df = pd.concat([new_df, encoded_df], axis=1)\n",
    "new_df.drop(columns=columns_to_encode, inplace=True)\n",
    "merged_encoded_df = new_df.to_csv('../data/merged_encoded_data_2020_election.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.read_csv('../output/merged_encoded_data_2020_election.csv')\n",
    "df = df.drop(columns=['state.1', 'name', 'fips', 'majority_Trump'], axis=1, inplace=False)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit_transform(df)\n",
    "df_imputed = pd.DataFrame(imp.fit_transform(df), columns=df.columns)\n",
    "X = df_imputed.drop('majority_Biden', axis=1, inplace=False)\n",
    "X = pd.DataFrame(scaler.fit_transform(X))\n",
    "y = df_imputed['majority_Biden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train / test split - Note that I dropped majority_Trump since Biden will be 0 or 1 indicating Trump or Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecting out the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 2s 4ms/step - loss: 0.3493 - accuracy: 0.8629\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9170\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9467\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9612\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9748\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9864\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 0.0418 - accuracy: 0.9851\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9905\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9913\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0236 - accuracy: 0.9922\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9934\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0180 - accuracy: 0.9959\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 0.9963\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9950\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9897\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9855\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9971\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 0.9988\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9992\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 9.8465e-04 - accuracy: 0.9996\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.3965e-04 - accuracy: 0.9996\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 7.4084e-04 - accuracy: 0.9996\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.2410e-04 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2818e-04 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.5312e-04 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 4.0078e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 3.4550e-04 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0627e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 2.7196e-04 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4545e-04 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.2030e-04 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9886e-04 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8343e-04 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6600e-04 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.5229e-04 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4055e-04 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2992e-04 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1978e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.1194e-04 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 0s 5ms/step - loss: 1.0513e-04 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 9.7703e-05 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 9.1865e-05 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.5617e-05 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 8.0457e-05 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.5731e-05 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 7.1579e-05 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.7490e-05 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.4620e-05 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 6.0798e-05 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.7642e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.4678e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 5.2040e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.9455e-05 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.7410e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.5123e-05 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 4.3025e-05 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 4.1019e-05 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.9058e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.7715e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.5934e-05 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.4343e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.3048e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.1628e-05 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 3.0301e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.9178e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.7954e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.6786e-05 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.5924e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4808e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.4004e-05 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.3024e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 2.2218e-05 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 2.1374e-05 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 2.0601e-05 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.9891e-05 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.9203e-05 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.8514e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7820e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.7270e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.6599e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.6084e-05 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5511e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.5054e-05 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4593e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.4048e-05 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.3561e-05 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.3160e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2707e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.2352e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1933e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.1570e-05 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 0s 3ms/step - loss: 1.1229e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0847e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 0s 4ms/step - loss: 1.0557e-05 - accuracy: 1.0000\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.9488\n",
      "Accuracy: 0.9488449096679688\n"
     ]
    }
   ],
   "source": [
    "# Let's architect out the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(161, input_dim=len(X_train.columns), activation='relu')) \n",
    "model.add(Dense(81, activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have heavily overfitted the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 19ms/step - loss: 1.1245 - accuracy: 0.6059 - val_loss: 0.8224 - val_accuracy: 0.8289\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.9288 - accuracy: 0.7417 - val_loss: 0.7883 - val_accuracy: 0.8351\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.8466 - accuracy: 0.7939 - val_loss: 0.7214 - val_accuracy: 0.8351\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.8030 - accuracy: 0.8208 - val_loss: 0.6837 - val_accuracy: 0.8433\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7582 - accuracy: 0.8316 - val_loss: 0.6337 - val_accuracy: 0.8474\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.7008 - accuracy: 0.8383 - val_loss: 0.5987 - val_accuracy: 0.8557\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6664 - accuracy: 0.8337 - val_loss: 0.5742 - val_accuracy: 0.8701\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6307 - accuracy: 0.8543 - val_loss: 0.5572 - val_accuracy: 0.8969\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5956 - accuracy: 0.8647 - val_loss: 0.5503 - val_accuracy: 0.8866\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5837 - accuracy: 0.8765 - val_loss: 0.5343 - val_accuracy: 0.8990\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5589 - accuracy: 0.8714 - val_loss: 0.5229 - val_accuracy: 0.8948\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5092 - accuracy: 0.8926 - val_loss: 0.5130 - val_accuracy: 0.9052\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4941 - accuracy: 0.9019 - val_loss: 0.5068 - val_accuracy: 0.8928\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4840 - accuracy: 0.8993 - val_loss: 0.5011 - val_accuracy: 0.8928\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4678 - accuracy: 0.9101 - val_loss: 0.4891 - val_accuracy: 0.8907\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4528 - accuracy: 0.9194 - val_loss: 0.4735 - val_accuracy: 0.9031\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4316 - accuracy: 0.9189 - val_loss: 0.4741 - val_accuracy: 0.9031\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.9205 - val_loss: 0.4652 - val_accuracy: 0.9072\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4079 - accuracy: 0.9308 - val_loss: 0.4577 - val_accuracy: 0.9093\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.9329 - val_loss: 0.4586 - val_accuracy: 0.9052\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3892 - accuracy: 0.9365 - val_loss: 0.4431 - val_accuracy: 0.9052\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.9292 - val_loss: 0.4402 - val_accuracy: 0.9155\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.9313 - val_loss: 0.4336 - val_accuracy: 0.9155\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3624 - accuracy: 0.9370 - val_loss: 0.4397 - val_accuracy: 0.9052\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3379 - accuracy: 0.9489 - val_loss: 0.4274 - val_accuracy: 0.9093\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.9478 - val_loss: 0.4277 - val_accuracy: 0.9072\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3358 - accuracy: 0.9483 - val_loss: 0.4236 - val_accuracy: 0.9093\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.9597 - val_loss: 0.4103 - val_accuracy: 0.9093\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3129 - accuracy: 0.9540 - val_loss: 0.4068 - val_accuracy: 0.9134\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3111 - accuracy: 0.9520 - val_loss: 0.4227 - val_accuracy: 0.9155\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3030 - accuracy: 0.9535 - val_loss: 0.4157 - val_accuracy: 0.9196\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2912 - accuracy: 0.9602 - val_loss: 0.3882 - val_accuracy: 0.9155\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2903 - accuracy: 0.9675 - val_loss: 0.3947 - val_accuracy: 0.9175\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2843 - accuracy: 0.9571 - val_loss: 0.4235 - val_accuracy: 0.9134\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2748 - accuracy: 0.9638 - val_loss: 0.4263 - val_accuracy: 0.9072\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2617 - accuracy: 0.9669 - val_loss: 0.4247 - val_accuracy: 0.9113\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2652 - accuracy: 0.9644 - val_loss: 0.4122 - val_accuracy: 0.9134\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2644 - accuracy: 0.9649 - val_loss: 0.4173 - val_accuracy: 0.9093\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2646 - accuracy: 0.9644 - val_loss: 0.3829 - val_accuracy: 0.9134\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2444 - accuracy: 0.9695 - val_loss: 0.4161 - val_accuracy: 0.9155\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2308 - accuracy: 0.9819 - val_loss: 0.4022 - val_accuracy: 0.9113\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2407 - accuracy: 0.9721 - val_loss: 0.3903 - val_accuracy: 0.9155\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2346 - accuracy: 0.9752 - val_loss: 0.4028 - val_accuracy: 0.9113\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2292 - accuracy: 0.9788 - val_loss: 0.3948 - val_accuracy: 0.9134\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2397 - accuracy: 0.9685 - val_loss: 0.4091 - val_accuracy: 0.9031\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2220 - accuracy: 0.9742 - val_loss: 0.4023 - val_accuracy: 0.9052\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2040 - accuracy: 0.9814 - val_loss: 0.4190 - val_accuracy: 0.9093\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2059 - accuracy: 0.9788 - val_loss: 0.4547 - val_accuracy: 0.9093\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1995 - accuracy: 0.9804 - val_loss: 0.4399 - val_accuracy: 0.9155\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.9241\n",
      "Accuracy: 0.9240924119949341\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(161, input_dim=len(X_train.columns), activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(81, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(40, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a grid CV search to optimise the best hyperparameters. Note: I have changed the evaluation metric to F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I want to oversample the minority class\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Odhran\\Documents\\statistical_analysis_3\\python_scripts\\data_set_up.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, Dropout\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscikit_learn\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mregularizers\u001b[39;00m \u001b[39mimport\u001b[39;00m l2\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.caallbacks import EarlyStopping\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Function to create model for KerasClassifier\n",
    "def create_model(dropout_rate=0.0, regularization_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(161, input_dim=len(X_train_resampled.columns), activation='relu', kernel_regularizer=l2(regularization_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=64, verbose=0)\n",
    "param_grid = {\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'regularization_rate': [0.001, 0.01],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [50, 100],\n",
    "    'init_mode': ['uniform', 'normal'],\n",
    "    'activation': ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=f1_scorer, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_resampled, y_train_resampled)\n",
    "print(f'Best F1 Score: {grid_result.best_score_} using {grid_result.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best F1 Score: 0.9748581014730419 using {'model__activation': 'relu', 'model__dropout_rate': 0.5, 'model__init_mode': 'normal', 'model__optimizer': 'adam', 'model__regularization_rate': 0.001}\n",
    "This is the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recreate and save the best model using different imbalance techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with Random Oversampling...\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 3s 8ms/step - loss: 0.6639 - accuracy: 0.7017\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.3838 - accuracy: 0.8833\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.3036 - accuracy: 0.9170\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 8ms/step - loss: 0.2572 - accuracy: 0.9373\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.2356 - accuracy: 0.9492\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.2159 - accuracy: 0.9529\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.2129 - accuracy: 0.9571\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.2017 - accuracy: 0.9594\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1787 - accuracy: 0.9653\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1861 - accuracy: 0.9613\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1633 - accuracy: 0.9715\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1684 - accuracy: 0.9683\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1595 - accuracy: 0.9715\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1572 - accuracy: 0.9693\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1491 - accuracy: 0.9740\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1426 - accuracy: 0.9767\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1565 - accuracy: 0.9718\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1357 - accuracy: 0.9772\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1292 - accuracy: 0.9824\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1397 - accuracy: 0.9784\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1259 - accuracy: 0.9819\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1367 - accuracy: 0.9812\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1175 - accuracy: 0.9864\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1115 - accuracy: 0.9869\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1219 - accuracy: 0.9827\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1174 - accuracy: 0.9864\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1130 - accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1154 - accuracy: 0.9864\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1032 - accuracy: 0.9886\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1076 - accuracy: 0.9859\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1143 - accuracy: 0.9839\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1088 - accuracy: 0.9874\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1016 - accuracy: 0.9884\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1008 - accuracy: 0.9896\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1016 - accuracy: 0.9876\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1173 - accuracy: 0.9804\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0988 - accuracy: 0.9886\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1068 - accuracy: 0.9879\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1026 - accuracy: 0.9896\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1022 - accuracy: 0.9884\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1099 - accuracy: 0.9859\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0979 - accuracy: 0.9906\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0983 - accuracy: 0.9901\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0970 - accuracy: 0.9903\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0943 - accuracy: 0.9896\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.0972 - accuracy: 0.9906\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0894 - accuracy: 0.9913\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0881 - accuracy: 0.9923\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0947 - accuracy: 0.9886\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0931 - accuracy: 0.9891\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0928 - accuracy: 0.9884\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0924 - accuracy: 0.9906\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1062 - accuracy: 0.9874\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.0975 - accuracy: 0.9871\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1013 - accuracy: 0.9881\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0933 - accuracy: 0.9918\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0911 - accuracy: 0.9918\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.0864 - accuracy: 0.9926\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0871 - accuracy: 0.9918\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0935 - accuracy: 0.9906\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0863 - accuracy: 0.9911\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1065 - accuracy: 0.9866\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1064 - accuracy: 0.9859\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1346 - accuracy: 0.9784\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1018 - accuracy: 0.9896\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1038 - accuracy: 0.9889\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1002 - accuracy: 0.9869\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0990 - accuracy: 0.9903\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.0990 - accuracy: 0.9893\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.9889\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0948 - accuracy: 0.9901\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "\n",
      "Results for Random Oversampling:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97       506\n",
      "         1.0       0.83      0.85      0.84       100\n",
      "\n",
      "    accuracy                           0.95       606\n",
      "   macro avg       0.90      0.91      0.90       606\n",
      "weighted avg       0.95      0.95      0.95       606\n",
      "\n",
      "Accuracy: 0.9455445544554455\n",
      "\n",
      "Model saved at ../models/best_model_Random Oversampling.joblib\n",
      "\n",
      "Training with Random Undersampling...\n",
      "Epoch 1/100\n",
      "13/13 [==============================] - 5s 13ms/step - loss: 0.7907 - accuracy: 0.5459\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.7374 - accuracy: 0.6514\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6437 - accuracy: 0.7605\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5243 - accuracy: 0.8387\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.4375 - accuracy: 0.8834\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.4042 - accuracy: 0.8784\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.3610 - accuracy: 0.9045\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.3474 - accuracy: 0.9107\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.3231 - accuracy: 0.9107\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.3072 - accuracy: 0.9231\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2860 - accuracy: 0.9305\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2700 - accuracy: 0.9355\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.2450 - accuracy: 0.9442\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2281 - accuracy: 0.9566\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 0.2352 - accuracy: 0.9491\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.2220 - accuracy: 0.9529\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2187 - accuracy: 0.9467\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 27ms/step - loss: 0.1821 - accuracy: 0.9677\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1937 - accuracy: 0.9591\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.2000 - accuracy: 0.9541\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1883 - accuracy: 0.9640\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1595 - accuracy: 0.9752\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1602 - accuracy: 0.9739\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1659 - accuracy: 0.9715\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1437 - accuracy: 0.9789\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1644 - accuracy: 0.9715\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1656 - accuracy: 0.9690\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1433 - accuracy: 0.9814\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1673 - accuracy: 0.9715\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1376 - accuracy: 0.9752\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1329 - accuracy: 0.9801\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1310 - accuracy: 0.9864\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1352 - accuracy: 0.9801\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1299 - accuracy: 0.9814\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1230 - accuracy: 0.9839\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.1179 - accuracy: 0.9888\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1238 - accuracy: 0.9901\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.1228 - accuracy: 0.9901\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1272 - accuracy: 0.9839\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1228 - accuracy: 0.9826\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1190 - accuracy: 0.9864\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1274 - accuracy: 0.9839\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.1123 - accuracy: 0.9926\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1279 - accuracy: 0.9814\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1046 - accuracy: 0.9913\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1171 - accuracy: 0.9901\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0983 - accuracy: 0.9963\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1061 - accuracy: 0.9938\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.1086 - accuracy: 0.9913\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1027 - accuracy: 0.9926\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0878 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.0962 - accuracy: 0.9950\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1216 - accuracy: 0.9864\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1005 - accuracy: 0.9926\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1307 - accuracy: 0.9876\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1318 - accuracy: 0.9826\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.1060 - accuracy: 0.9901\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0995 - accuracy: 0.9913\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.1035 - accuracy: 0.9913\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.1177 - accuracy: 0.9876\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1022 - accuracy: 0.9913\n",
      "19/19 [==============================] - 0s 7ms/step\n",
      "\n",
      "Results for Random Undersampling:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95       506\n",
      "         1.0       0.69      0.92      0.79       100\n",
      "\n",
      "    accuracy                           0.92       606\n",
      "   macro avg       0.83      0.92      0.87       606\n",
      "weighted avg       0.93      0.92      0.92       606\n",
      "\n",
      "Accuracy: 0.9174917491749175\n",
      "\n",
      "Training with SMOTE...\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 4s 9ms/step - loss: 0.6467 - accuracy: 0.7272\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.3763 - accuracy: 0.8927\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.2882 - accuracy: 0.9289\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.2519 - accuracy: 0.9465\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.2213 - accuracy: 0.9512\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.2144 - accuracy: 0.9569\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1920 - accuracy: 0.9666\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.1832 - accuracy: 0.9631\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1765 - accuracy: 0.9705\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1623 - accuracy: 0.9718\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1606 - accuracy: 0.9727\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1592 - accuracy: 0.9745\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1542 - accuracy: 0.9760\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1546 - accuracy: 0.9784\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1487 - accuracy: 0.9745\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1374 - accuracy: 0.9799\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1365 - accuracy: 0.9812\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1355 - accuracy: 0.9797\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1290 - accuracy: 0.9809\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1187 - accuracy: 0.9841\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1327 - accuracy: 0.9832\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 1s 8ms/step - loss: 0.1137 - accuracy: 0.9891\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1111 - accuracy: 0.9854\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1110 - accuracy: 0.9856\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1159 - accuracy: 0.9841\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1087 - accuracy: 0.9874\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1131 - accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1069 - accuracy: 0.9884\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0981 - accuracy: 0.9911\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1028 - accuracy: 0.9911\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1027 - accuracy: 0.9881\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.0972 - accuracy: 0.9913\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1056 - accuracy: 0.9871\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1047 - accuracy: 0.9881\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1206 - accuracy: 0.9822\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1077 - accuracy: 0.9889\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1007 - accuracy: 0.9889\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1086 - accuracy: 0.9844\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 1s 10ms/step - loss: 0.1040 - accuracy: 0.9871\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1065 - accuracy: 0.9881\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 0.1049 - accuracy: 0.9898\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 1s 11ms/step - loss: 0.1004 - accuracy: 0.9884\n",
      "19/19 [==============================] - 0s 5ms/step\n",
      "\n",
      "Results for SMOTE:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97       506\n",
      "         1.0       0.83      0.86      0.85       100\n",
      "\n",
      "    accuracy                           0.95       606\n",
      "   macro avg       0.90      0.91      0.91       606\n",
      "weighted avg       0.95      0.95      0.95       606\n",
      "\n",
      "Accuracy: 0.9488448844884488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I want to test the different imbalance techniques with the best model\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from joblib import dump\n",
    "\n",
    "\n",
    "# Random Oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Random Undersampling\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Define the model with the best hyperparameters\n",
    "def create_best_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(161, input_dim=len(X_train_resampled.columns), activation='relu', kernel_initializer='normal', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    for i in range(3 - 1):\n",
    "        model.add(Dense(161 // (2 ** (i + 1)), activation='relu', kernel_initializer='normal', kernel_regularizer=l2(0.001)))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train and evaluate the model with different resampling techniques\n",
    "resampling_techniques = {\n",
    "    'Random Oversampling': (X_ros, y_ros),\n",
    "    'Random Undersampling': (X_rus, y_rus),\n",
    "    'SMOTE': (X_smote, y_smote)\n",
    "}\n",
    "\n",
    "for technique_name, (X_sampled, y_sampled) in resampling_techniques.items():\n",
    "    print(f\"Training with {technique_name}...\")\n",
    "\n",
    "    # Create and train the model\n",
    "    model = create_best_model()\n",
    "    model.fit(X_sampled, y_sampled, epochs=100, batch_size=64, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    print(f\"\\nResults for {technique_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\\n\")\n",
    "\n",
    "    # Optionally save the model\n",
    "    if technique_name == 'Random Oversampling':\n",
    "        model_path = f\"../models/best_model_{technique_name}.joblib\"\n",
    "        dump(model, model_path)\n",
    "        print(f\"Model saved at {model_path}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Results for Random Oversampling:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.97      0.97       506\n",
    "         1.0       0.84      0.85      0.85       100\n",
    "\n",
    "    accuracy                           0.95       606\n",
    "   macro avg       0.91      0.91      0.91       606\n",
    "weighted avg       0.95      0.95      0.95       606\n",
    "\n",
    "Accuracy: 0.9488448844884488\n",
    "\n",
    "\n",
    "Results for Random Undersampling:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.99      0.90      0.94       506\n",
    "         1.0       0.65      0.94      0.77       100\n",
    "\n",
    "    accuracy                           0.91       606\n",
    "   macro avg       0.82      0.92      0.85       606\n",
    "weighted avg       0.93      0.91      0.91       606\n",
    "\n",
    "Accuracy: 0.905940594059406\n",
    "\n",
    "Results for SMOTE:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.96      0.97      0.97       506\n",
    "         1.0       0.85      0.80      0.82       100\n",
    "\n",
    "    accuracy                           0.94       606\n",
    "   macro avg       0.91      0.89      0.90       606\n",
    "weighted avg       0.94      0.94      0.94       606\n",
    "\n",
    "Accuracy: 0.9438943894389439\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_resampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Odhran\\Documents\\statistical_analysis_3\\python_scripts\\data_set_up.ipynb Cell 24\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X32sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m f1_scorer \u001b[39m=\u001b[39m make_scorer(f1_score)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X32sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, scoring\u001b[39m=\u001b[39mf1_scorer, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X32sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39mfit(X_train_resampled, y_train_resampled)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Odhran/Documents/statistical_analysis_3/python_scripts/data_set_up.ipynb#X32sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest F1 Score: \u001b[39m\u001b[39m{\u001b[39;00mgrid_result\u001b[39m.\u001b[39mbest_score_\u001b[39m}\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m{\u001b[39;00mgrid_result\u001b[39m.\u001b[39mbest_params_\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_resampled' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "def create_model(dropout_rate=0.0, regularization_rate=0.0, optimizer='adam', init_mode='uniform', activation='relu', neurons=161, layers=3, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=len(X_train_resampled.columns), activation=activation, kernel_initializer=init_mode, kernel_regularizer=l2(regularization_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    for i in range(layers - 1):\n",
    "        model.add(Dense(neurons // (2 ** (i + 1)), activation=activation, kernel_initializer=init_mode, kernel_regularizer=l2(regularization_rate)))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=create_model, epochs=100, batch_size=64, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "param_grid = {\n",
    "    'model__dropout_rate': [0.2, 0.3, 0.4, 0.5],\n",
    "    'model__regularization_rate': [0.001, 0.01, 0.05],\n",
    "    'model__optimizer': ['adam', 'sgd'],\n",
    "    'model__init_mode': ['uniform', 'normal', 'he_normal'],\n",
    "    'model__activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'model__neurons': [50, 100, 150],\n",
    "    'model__layers': [2, 3, 4],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'epochs': [50, 100, 150],\n",
    "    'model__learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=f1_scorer, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_resampled, y_train_resampled)\n",
    "print(f'Best F1 Score: {grid_result.best_score_} using {grid_result.best_params_}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
